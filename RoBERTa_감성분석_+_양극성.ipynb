{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSvhZ8bzosDwO5+48p1+Ab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeungNap/test2/blob/main/RoBERTa_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D_%2B_%EC%96%91%EA%B7%B9%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa ê°ì„±ë¶„ì„"
      ],
      "metadata": {
        "id": "RCUDSomPvG0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzs5Tz7du8hZ"
      },
      "outputs": [],
      "source": [
        "# ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install scipy transformers pandas openpyxl tqdm matplotlib datasets scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# ğŸ“„ ë°ì´í„° ë¡œë”©\n",
        "df = pd.read_excel(filename)\n",
        "if 'Review' not in df.columns:\n",
        "    raise ValueError(\"âŒ 'Review' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "df['Review'] = df['Review'].fillna(\"\")\n",
        "\n",
        "# ğŸ¤– ëª¨ë¸ ë¡œë“œ\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
        "\n",
        "# âœ… ê°ì„± ë¶„ì„ í•¨ìˆ˜ (batch)\n",
        "def analyze_sentiment_batch(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = softmax(outputs.logits.cpu().numpy(), axis=1)\n",
        "    return probs  # shape: (batch_size, 3)\n",
        "\n",
        "# ğŸ”„ ë°°ì¹˜ ê°ì„± ë¶„ì„\n",
        "batch_size = 32\n",
        "scores = []\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_texts = df['Review'].iloc[i:i+batch_size].tolist()\n",
        "    try:\n",
        "        probs = analyze_sentiment_batch(batch_texts)\n",
        "        for prob in probs:\n",
        "            pos, neu, neg = prob[2], prob[1], prob[0]\n",
        "            # compound ê³„ì‚°\n",
        "            compound = round((pos - neg) * (1 - neu), 4)\n",
        "            scores.append(compound)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ at batch {i}: {e}\")\n",
        "        scores.extend([0.0] * len(batch_texts))\n",
        "\n",
        "df['sentiment_score'] = scores\n",
        "\n",
        "# âœ… ë¶„ìœ„ìˆ˜ ê³„ì‚° (25%, 75%)\n",
        "q25 = df['sentiment_score'].quantile(0.25)\n",
        "q75 = df['sentiment_score'].quantile(0.75)\n",
        "\n",
        "print(f\"ğŸ¯ ë¶„ìœ„ìˆ˜ ê¸°ì¤€: Q25={q25:.4f}, Q75={q75:.4f}\")\n",
        "\n",
        "# ğŸ”„ ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ë¼ë²¨ë§ í•¨ìˆ˜\n",
        "def label_sentiment(score):\n",
        "    if score <= q25:\n",
        "        return 2  # Negative\n",
        "    elif score >= q75:\n",
        "        return 1  # Positive\n",
        "    else:\n",
        "        return 3  # Neutral\n",
        "\n",
        "df['sentiment_label'] = df['sentiment_score'].apply(label_sentiment)\n",
        "\n",
        "# ğŸ’¾ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
        "output_file = filename.replace(\".xlsx\", \"_roberta_sentiment_labeled.xlsx\")\n",
        "df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n",
        "\n",
        "print(f\"âœ… ì™„ë£Œ: RoBERTa ê°ì„± ë¶„ì„ + ë¶„ìœ„ìˆ˜ ë¼ë²¨ë§ (1=Positiveâ‰¥{q75:.2f}, 2=Negativeâ‰¤{q25:.2f}, 3=Neutral)\")\n"
      ],
      "metadata": {
        "id": "fzRc0vMPvRp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta ì–‘ê·¹ì„±"
      ],
      "metadata": {
        "id": "bwZEPI_uvhbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# ğŸ“„ ë°ì´í„° ë¡œë”©\n",
        "df = pd.read_excel(filename)\n",
        "if 'Review_Raw' not in df.columns:\n",
        "    raise ValueError(\"âŒ 'Review_Raw' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "df['Review_Raw'] = df['Review_Raw'].fillna(\"\")\n",
        "\n",
        "# ğŸ¤– ëª¨ë¸ ë¡œë“œ\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
        "\n",
        "# âœ… ê°ì„± ë¶„ì„ í•¨ìˆ˜ (batch ì²˜ë¦¬)\n",
        "def analyze_sentiment_batch(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    probs = softmax(outputs.logits.cpu().numpy(), axis=1)\n",
        "    return probs  # shape: (batch_size, 3)\n",
        "\n",
        "# âœ… ë°°ì¹˜ ì‹¤í–‰\n",
        "batch_size = 32\n",
        "polarity_scores = []\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_texts = df['Review_Raw'].iloc[i:i+batch_size].tolist()\n",
        "    try:\n",
        "        probs = analyze_sentiment_batch(batch_texts)\n",
        "        for prob in probs:\n",
        "            pos = float(prob[2])\n",
        "            neg = float(prob[0])\n",
        "            polarity = round(abs(pos - neg), 4)  # ì–‘ê·¹ì„± ê°•ë„: 0~1\n",
        "            polarity_scores.append(polarity)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ at batch {i}: {e}\")\n",
        "        polarity_scores.extend([0.0] * len(batch_texts))\n",
        "\n",
        "# âœ… ê²°ê³¼ ì €ì¥ (Polarity_Scoreë§Œ í¬í•¨)\n",
        "df_result = pd.DataFrame({\n",
        "    'Polarity_Score': polarity_scores\n",
        "})\n",
        "\n",
        "output_file = filename.replace(\".xlsx\", \"_roberta_polarity_score_0to1.xlsx\")\n",
        "df_result.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"âœ… ì™„ë£Œ: 0~1 ë²”ìœ„ì˜ Polarity_Score ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "sXp958JgvYTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}